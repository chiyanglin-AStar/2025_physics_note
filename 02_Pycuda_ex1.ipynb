{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPiy7ZO5iTBqyllRfkFuLkY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chiyanglin-AStar/2025_physics_note/blob/main/02_Pycuda_ex1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook is reference from [Linking Python to CUDA with PyCUDA: [PyCuda  Tutorial](https://documen.tician.de/pycuda/tutorial.html)"
      ],
      "metadata": {
        "id": "TYkCCYwQ6CAy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PyCUDA ref:\n",
        "\n",
        "[PyCUDA Tutorial(翻譯)](https://hackmd.io/@shaoeChen/SkbmZOXbB/https%3A%2F%2Fhackmd.io%2F%40shaoeChen%2FSkKb0fX-H)\n",
        "\n",
        "[pycuda tutorial](https://documen.tician.de/pycuda/tutorial.html)\n",
        "\n",
        "[PyCUDA Tutorial Introduction](https://github.com/berlinguyinca/pycuda/blob/master/doc/source/tutorial.rst)\n",
        "\n",
        "[GPU程式設計(5) -- Python](https://ithelp.ithome.com.tw/articles/10283144)"
      ],
      "metadata": {
        "id": "eHxi2lduBmsJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ccx8W2s96AUX",
        "outputId": "6fd74acc-538f-47a6-fcf8-db7ed07b2b79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pycuda\n",
            "  Downloading pycuda-2024.1.2.tar.gz (1.7 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.7 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m52.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pytools>=2011.2 (from pycuda)\n",
            "  Downloading pytools-2024.1.21-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: platformdirs>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from pycuda) (4.3.6)\n",
            "Collecting mako (from pycuda)\n",
            "  Downloading Mako-1.3.8-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.5 in /usr/local/lib/python3.10/dist-packages (from pytools>=2011.2->pycuda) (4.12.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from mako->pycuda) (3.0.2)\n",
            "Downloading pytools-2024.1.21-py3-none-any.whl (92 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.4/92.4 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Mako-1.3.8-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pycuda\n",
            "  Building wheel for pycuda (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycuda: filename=pycuda-2024.1.2-cp310-cp310-linux_x86_64.whl size=660545 sha256=6aa0b44340df9123e1c544a0e72b09741afab15eb91d430af33022123d94d5ea\n",
            "  Stored in directory: /root/.cache/pip/wheels/70/63/40/4bf006182f942d3516b71bb2ff3b57ccbdb8b2c0ee81882b6e\n",
            "Successfully built pycuda\n",
            "Installing collected packages: pytools, mako, pycuda\n",
            "Successfully installed mako-1.3.8 pycuda-2024.1.2 pytools-2024.1.21\n"
          ]
        }
      ],
      "source": [
        "!pip install pycuda"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Getting started"
      ],
      "metadata": {
        "id": "5j7LucawF8fT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pycuda.driver as cuda\n",
        "import pycuda.autoinit\n",
        "from pycuda.compiler import SourceModule"
      ],
      "metadata": {
        "id": "ANyB4u68F_Ag"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transferring Data\n",
        "\n",
        "The next step in most programs is to transfer data onto the device. In PyCuda, you will mostly transfer data from numpy arrays on the host. (But indeed, everything that satisfies the Python buffer interface will work, even bytes.) Let’s make a 4x4 array of random numbers:"
      ],
      "metadata": {
        "id": "PNT03emdGPNq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy\n",
        "a = numpy.random.randn(4,4)"
      ],
      "metadata": {
        "id": "yxTCfSWzGerY"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "But wait–a consists of double precision numbers, but most nVidia devices only support single precision:"
      ],
      "metadata": {
        "id": "reTBwVyqHLQ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = a.astype(numpy.float32)"
      ],
      "metadata": {
        "id": "B_Nx3hffG0ld"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, we need somewhere to transfer data to, so we need to allocate memory on the device:"
      ],
      "metadata": {
        "id": "nIy8XFcTHF1l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a_gpu = cuda.mem_alloc(a.nbytes)"
      ],
      "metadata": {
        "id": "2iD8XiR8G19N"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As a last step, we need to transfer the data to the GPU:"
      ],
      "metadata": {
        "id": "r_o80P-KHEFH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cuda.memcpy_htod(a_gpu, a)"
      ],
      "metadata": {
        "id": "dv3mxzLTG80V"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Executing a Kernel\n",
        "For this tutorial, we’ll stick to something simple: We will write code to double each entry in a_gpu. To this end, we write the corresponding CUDA C code, and feed it into the constructor of a pycuda.compiler.SourceModule:"
      ],
      "metadata": {
        "id": "zO9fR5pBHTya"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mod = SourceModule(\"\"\"\n",
        "  __global__ void doublify(float *a)\n",
        "  {\n",
        "    int idx = threadIdx.x + threadIdx.y*4;\n",
        "    a[idx] *= 2;\n",
        "  }\n",
        "  \"\"\")"
      ],
      "metadata": {
        "id": "d62xBEavHZi1"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If there aren’t any errors, the code is now compiled and loaded onto the device. We find a reference to our pycuda.driver.Function and call it, specifying a_gpu as the argument, and a block size of 4x4:"
      ],
      "metadata": {
        "id": "7kyXG77JHes9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "func = mod.get_function(\"doublify\")\n",
        "func(a_gpu, block=(4,4,1))"
      ],
      "metadata": {
        "id": "KswNrdzVHiQ9"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, we fetch the data back from the GPU and display it, together with the original a:"
      ],
      "metadata": {
        "id": "C-1Tcd6kHl3N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a_doubled = numpy.empty_like(a)\n",
        "cuda.memcpy_dtoh(a_doubled, a_gpu)\n",
        "print(a_doubled)\n",
        "print(a)"
      ],
      "metadata": {
        "id": "f9eJOXLNH3nu",
        "outputId": "fd78a120-31ed-4437-97fd-04a3cbf90863",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0.46608397 -1.261564   -0.05711028  3.14196   ]\n",
            " [-2.1014385  -5.111447   -0.59766185  1.3984003 ]\n",
            " [-0.1855822   0.04879789  0.6932547  -3.217177  ]\n",
            " [ 1.0169098   0.01087349 -0.40107808  2.1073337 ]]\n",
            "[[ 0.23304199 -0.630782   -0.02855514  1.57098   ]\n",
            " [-1.0507193  -2.5557234  -0.29883093  0.69920015]\n",
            " [-0.0927911   0.02439895  0.34662735 -1.6085885 ]\n",
            " [ 0.5084549   0.00543674 -0.20053904  1.0536668 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "his will print something like this:\n",
        "```\n",
        "[[ 0.51360393  1.40589952  2.25009012  3.02563429]\n",
        " [-0.75841576 -1.18757617  2.72269917  3.12156057]\n",
        " [ 0.28826082 -2.92448163  1.21624792  2.86353827]\n",
        " [ 1.57651746  0.63500965  2.21570683 -0.44537592]]\n",
        "[[ 0.25680196  0.70294976  1.12504506  1.51281714]\n",
        " [-0.37920788 -0.59378809  1.36134958  1.56078029]\n",
        " [ 0.14413041 -1.46224082  0.60812396  1.43176913]\n",
        " [ 0.78825873  0.31750482  1.10785341 -0.22268796]]\n",
        "```\n",
        "\n",
        "It worked! That completes our walkthrough. Thankfully, PyCuda takes over from here and does all the cleanup for you, so you’re done. Stick around for some bonus material in the next section, though.\n",
        "\n",
        "(You can find the code for this demo as examples/demo.py in the PyCuda source distribution.)"
      ],
      "metadata": {
        "id": "iIFqqQa0H9z9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Shortcuts for Explicit Memory Copies\n",
        "The pycuda.driver.In, pycuda.driver.Out, and pycuda.driver.InOut argument handlers can simplify some of the memory transfers. For example, instead of creating a_gpu, if replacing a is fine, the following code can be used:"
      ],
      "metadata": {
        "id": "E0qeLeBSJSnN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "func(cuda.InOut(a), block=(4, 4, 1))"
      ],
      "metadata": {
        "id": "6WX43hx1JbPt"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepared Invocations\n",
        "Function invocation using the built-in pycuda.driver.Function.__call__() method incurs overhead for type identification (see Device Interface). To achieve the same effect as above without this overhead, the function is bound to argument types (as designated by Python’s standard library struct module), and then called. This also avoids having to assign explicit argument sizes using the numpy.number classes:"
      ],
      "metadata": {
        "id": "DW6Gj2LkJikJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "grid = (1, 1)\n",
        "block = (4, 4, 1)\n",
        "func.prepare(\"P\")\n",
        "func.prepared_call(grid, block, a_gpu)"
      ],
      "metadata": {
        "id": "6N7CK5s3Ju0V"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bonus: Abstracting Away the Complications\n",
        "Using a pycuda.gpuarray.GPUArray, the same effect can be achieved with much less writing:"
      ],
      "metadata": {
        "id": "uEbEJTbqJ4Yu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pycuda.gpuarray as gpuarray\n",
        "import pycuda.driver as cuda\n",
        "import pycuda.autoinit\n",
        "import numpy\n",
        "\n",
        "a_gpu = gpuarray.to_gpu(numpy.random.randn(4,4).astype(numpy.float32))\n",
        "a_doubled = (2*a_gpu).get()\n",
        "print(a_doubled)\n",
        "print(a_gpu)"
      ],
      "metadata": {
        "id": "4S3yjGlQKHtt",
        "outputId": "881aeb7f-1961-4ecc-d3ff-2b5bb1e3dbf2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/google/colab/_variable_inspector.py:27: UserWarning: device_allocation in out-of-thread context could not be cleaned up\n",
            "  globals().clear()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-1.795199   -0.99280566  2.4260628   2.4114265 ]\n",
            " [-0.75836754  1.299085   -0.3551251   0.06969641]\n",
            " [ 1.0779378  -0.39955267  1.2220305   0.18321636]\n",
            " [-3.310843    0.09009165 -0.8409423   0.6559306 ]]\n",
            "[[-0.8975995  -0.49640283  1.2130314   1.2057133 ]\n",
            " [-0.37918377  0.6495425  -0.17756255  0.03484821]\n",
            " [ 0.5389689  -0.19977634  0.61101526  0.09160818]\n",
            " [-1.6554215   0.04504583 -0.42047116  0.3279653 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "TZT--joGJtwX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Advanced Topics\n",
        "### Structures\n",
        "(contributed by Nicholas Tung, find the code in examples/demo_struct.py)\n",
        "\n",
        "Suppose we have the following structure, for doubling a number of variable length arrays:"
      ],
      "metadata": {
        "id": "_omOdAG7KM84"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mod = SourceModule(\"\"\"\n",
        "    struct DoubleOperation {\n",
        "        int datalen, __padding; // so 64-bit ptrs can be aligned\n",
        "        float *ptr;\n",
        "    };\n",
        "\n",
        "    __global__ void double_array(DoubleOperation *a) {\n",
        "        a = &a[blockIdx.x];\n",
        "        for (int idx = threadIdx.x; idx < a->datalen; idx += blockDim.x) {\n",
        "            a->ptr[idx] *= 2;\n",
        "        }\n",
        "    }\n",
        "    \"\"\")"
      ],
      "metadata": {
        "id": "pZHPhEzAKjZ9"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Each block in the grid (see CUDA documentation) will double one of the arrays. The for loop allows for more data elements than threads to be doubled, though is not efficient if one can guarantee that there will be a sufficient number of threads. Next, a wrapper class for the structure is created, and two arrays are instantiated:"
      ],
      "metadata": {
        "id": "Q_s0KEXbKor9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DoubleOpStruct:\n",
        "    mem_size = 8 + numpy.intp(0).nbytes\n",
        "    def __init__(self, array, struct_arr_ptr):\n",
        "        self.data = cuda.to_device(array)\n",
        "        self.shape, self.dtype = array.shape, array.dtype\n",
        "        packed_args = struct.pack(\"ixP\", array.size, numpy.uintp(self.data))\n",
        "        cuda.memcpy_htod(struct_arr_ptr, packed_args)\n",
        "\n",
        "    def __str__(self):\n",
        "        return str(cuda.from_device(self.data, self.shape, self.dtype))\n",
        "\n",
        "struct_arr = cuda.mem_alloc(2 * DoubleOpStruct.mem_size)\n",
        "do2_ptr = int(struct_arr) + DoubleOpStruct.mem_size\n",
        "\n",
        "array1 = DoubleOpStruct(numpy.array([1, 2, 3], dtype=numpy.float32), struct_arr)\n",
        "array2 = DoubleOpStruct(numpy.array([0, 4], dtype=numpy.float32), do2_ptr)\n",
        "print(\"original arrays\", array1, array2)"
      ],
      "metadata": {
        "id": "sac7wYajKtI9",
        "outputId": "c6914418-9912-4af4-e1ef-6a976bd454c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'struct' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-aa44266939d4>\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mdo2_ptr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstruct_arr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mDoubleOpStruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmem_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0marray1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDoubleOpStruct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstruct_arr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0marray2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDoubleOpStruct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdo2_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"original arrays\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marray1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marray2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-aa44266939d4>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, array, struct_arr_ptr)\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mpacked_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ixP\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muintp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemcpy_htod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstruct_arr_ptr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpacked_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'struct' is not defined"
          ]
        }
      ]
    }
  ]
}